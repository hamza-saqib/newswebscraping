{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "from datetime import date\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['title','category', 'chanel', 'permalink', 'image_src', 'date_time', 'description', 'fetching_date', 'language']\n",
    "rows, cols = (0, 9)\n",
    "data = [[0]*cols]*rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [[\"https://www.dawn.com/trends/coronavirus\", \"Health\", \"Dawn\"],\n",
    "           [\"https://www.dawn.com/sport\", \"Sports\", \"Dawn\"], \n",
    "           [\"https://www.dawn.com/world\", \"International\", \"Dawn\"],\n",
    "           [\"https://images.dawn.com/art-culture\", \"Culture\", \"Dawn\"],\n",
    "           [\"https://www.dawn.com/trends/coronavirus\", \"IT/Science\", \"Dawn\"]]\n",
    "#sourceHtml = requests.get(sources[1][0]).text\n",
    "#soup = BeautifulSoup(sourceHtml, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for source in sources:\n",
    "    #print('i' + str(i))\n",
    "    j=0\n",
    "    \n",
    "    sourceHtml = requests.get(source[0]).text\n",
    "    soup = BeautifulSoup(sourceHtml, 'lxml')\n",
    "    for article in soup.find_all('article', class_='box'):\n",
    "        #print('j' + str(j))\n",
    "        j = j +1\n",
    "        i=i+1\n",
    "        try:\n",
    "            title = article.h2.a.text.splitlines()[-1]\n",
    "            try:\n",
    "                permalink = article.find('a', class_='story__link')['href']\n",
    "            except:\n",
    "                permalink = ''\n",
    "            try:\n",
    "                image_src = article.figure.div.a.picture.img['src']\n",
    "            except:\n",
    "                image_src = ''\n",
    "            try:\n",
    "                date_time = article.find('span', class_='timestamp--time').text\n",
    "            except:\n",
    "                date_time = ''\n",
    "            try:\n",
    "                description = article.find('div', class_='story__excerpt').text.splitlines()[0]\n",
    "            except:\n",
    "                description = ''\n",
    "            data.append([title, source[1], source[2], permalink, image_src, date_time, description, date.today(), 'English'])\n",
    "        except:\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources2 = [[\"https://arynews.tv/en/category/international-2\", \"International\", \"ARY\"],\n",
    "            [\"https://arynews.tv/en/category/sci-techno/\", \"IT/Science\", \"ARY\"], \n",
    "            [\"https://arynews.tv/en/category/health-2/\", \"Health\", \"ARY\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "#sourceHtml = requests.get(sources2[1][0], headers=headers).text\n",
    "#soup2 = BeautifulSoup(sourceHtml, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for source in sources2:\n",
    "    #print('i' + str(i))\n",
    "    j=0\n",
    "    \n",
    "    sourceHtml = requests.get(source[0], headers=headers).text\n",
    "    soup = BeautifulSoup(sourceHtml, 'lxml')\n",
    "    for article2 in soup.find_all('article', class_='type-post'):\n",
    "        #print('j' + str(j))\n",
    "        j = j +1\n",
    "        i=i+1\n",
    "        try:\n",
    "            title = article2.div.h2.text\n",
    "        except:\n",
    "            title = ''\n",
    "        try:\n",
    "            permalink = article2.div.find('div', class_='featured').a['href']\n",
    "            \n",
    "        except:\n",
    "            permalink = ''\n",
    "        try:\n",
    "            image_src = article2.div.find('div', class_='featured').a['data-src']\n",
    "        except:\n",
    "            image_src = ''\n",
    "        try:\n",
    "            date_time = article2.div.text.splitlines()[-2]\n",
    "        except:\n",
    "            date_time = ''\n",
    "        try:\n",
    "            description = article2.div.find('div', class_='post-summary').text\n",
    "        except:\n",
    "            description = ''\n",
    "        data.append([title, source[1], source[2], permalink, image_src, date_time, description, date.today(), 'English'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources3 = [[\"https://www.geo.tv/category/world\", \"International\", \"GEO\"],\n",
    "            [\"https://www.geo.tv/category/sci-tech\", \"IT/Science\", \"GEO\"], \n",
    "            [\"https://www.geo.tv/category/sports\", \"Sports\", \"GEO\"],\n",
    "            [\"https://www.geo.tv/category/entertainment\", \"Entertainment\", \"GEO\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceHtml = requests.get(sources3[0][0]).text\n",
    "soup = BeautifulSoup(sourceHtml, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for source in sources3:\n",
    "    #print('i' + str(i))\n",
    "    j=0\n",
    "    \n",
    "    sourceHtml = requests.get(source[0]).text\n",
    "    soup = BeautifulSoup(sourceHtml, 'lxml')\n",
    "    for article in soup.find_all('div', class_='singleBlock'):\n",
    "        #print('j' + str(j))\n",
    "        j = j +1\n",
    "        i=i+1\n",
    "        try:\n",
    "            title = article.div.ul.li.a.find('div', class_='entry-content-heading').div.h2.text\n",
    "        except:\n",
    "            title = ''\n",
    "        try:\n",
    "            permalink = article.div.ul.li.a['href']\n",
    "        except:\n",
    "            permalink = ''\n",
    "            print('ex---')\n",
    "        try:\n",
    "            image_src = article.div.ul.li.a.find('div', class_='pic').img['src']\n",
    "        except:\n",
    "            image_src = ''\n",
    "        try:\n",
    "            date_time = article.div.ul.li.a.find('div', class_='entry-content-heading').div.span.text\n",
    "        except:\n",
    "            date_time = ''\n",
    "        try:\n",
    "            description = ''\n",
    "        except:\n",
    "            description = ''\n",
    "        data.append([title, source[1], source[2], permalink, image_src, date_time, description, date.today(), 'English'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources4 = [[\"https://ptv.com.pk/ptvWorld/news/National\", \"National/Local\", \"PTV\"],\n",
    "            [\"https://ptv.com.pk/ptvWorld/news/Cricket\", \"Sports\", \"PTV\"], \n",
    "            [\"https://ptv.com.pk/ptvWorld/news/International\", \"International\", \"PTV\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for source in sources4:\n",
    "    #print('i' + str(i))\n",
    "    j=0\n",
    "    \n",
    "    sourceHtml = requests.get(source[0]).text\n",
    "    soup = BeautifulSoup(sourceHtml, 'lxml')\n",
    "    for article in soup.find_all('ul', class_='big'):\n",
    "        #print('j' + str(j))\n",
    "        j = j +1\n",
    "        i=i+1\n",
    "        try:\n",
    "            title = article.li.div.div.h4.a.text.splitlines()[-1]\n",
    "        except:\n",
    "            title = ''\n",
    "        try:\n",
    "            permalink = article.li.div.div.h4.a['href']\n",
    "            \n",
    "        except:\n",
    "            permalink = ''\n",
    "        try:\n",
    "            image_src = article.li.img['src']\n",
    "        except:\n",
    "            image_src = ''\n",
    "        try:\n",
    "            date_time = article.li.div.div.ul.li.text.splitlines()[-1]\n",
    "        except:\n",
    "            date_time = ''\n",
    "        try:\n",
    "            description = article.li.div.div.p.text.splitlines()[-1]\n",
    "        except:\n",
    "            description = ''\n",
    "        data.append([title, source[1], source[2], permalink, image_src, date_time, description, date.today(), 'English'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources5 = [[\"https://www.express.pk/health/\", \"Health\", \"Express\"],\n",
    "            [\"https://www.express.pk/sports/\", \"Sports\", \"Express\"], \n",
    "            [\"https://www.express.pk/world/\", \"International\", \"Express\"],\n",
    "            [\"https://www.express.pk/science/\", \"IT/Science\", \"Express\"],\n",
    "            [\"https://www.express.pk/pakistan/\", \"National/Local\", \"Express\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for source in sources5:\n",
    "    #print('i' + str(i))\n",
    "    j=0\n",
    "    \n",
    "    sourceHtml = requests.get(source[0]).text\n",
    "    soup = BeautifulSoup(sourceHtml, 'lxml')\n",
    "    for article in soup.find_all('div', class_='cstoreyitem'):\n",
    "        #print('j' + str(j))\n",
    "        j = j +1\n",
    "        i=i+1\n",
    "        try:\n",
    "            title = article.div.a.find_next_sibling(\"a\").text\n",
    "        except:\n",
    "            title = ''\n",
    "        try:\n",
    "            permalink = article.div.a['href']\n",
    "            \n",
    "        except:\n",
    "            permalink = ''\n",
    "        try:\n",
    "            image_src = article.div.a.img['src']\n",
    "        except:\n",
    "            image_src = ''\n",
    "        try:\n",
    "            date_time = ''\n",
    "        except:\n",
    "            date_time = ''\n",
    "        try:\n",
    "            description = article.div.a.img['alt']\n",
    "        except:\n",
    "            description = ''\n",
    "        data.append([title, source[1], source[2], permalink, image_src, date_time, description, date.today(), 'Urdu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources6 = [[\"https://www.samaa.tv/lifeandstyle/\", \"LifeStyle/Culture\", \"SAMAA\"],\n",
    "            [\"https://www.samaa.tv/sports/\", \"Sports\", \"SAMAA\"], \n",
    "            [\"https://www.samaa.tv/news/\", \"Local\", \"SAMAA\"],\n",
    "            [\"https://www.samaa.tv/technology/\", \"IT/Science\", \"SAMAA\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these webpages have different style of posts on top\n",
    "i = 0\n",
    "for source in sources6:\n",
    "    #print('i' + str(i))\n",
    "    j=0\n",
    "    \n",
    "    sourceHtml = requests.get(source[0]).text\n",
    "    soup = BeautifulSoup(sourceHtml, 'lxml')\n",
    "    \n",
    "    first_article = soup.find_all('div', class_='col-md-12')[2].find('div', class_='row')\n",
    "    try:\n",
    "        title = first_article.a['title']\n",
    "    except:\n",
    "        title = ''\n",
    "    try:\n",
    "        permalink = first_article.a['href']\n",
    "\n",
    "    except:\n",
    "        permalink = ''\n",
    "    try:\n",
    "        image_src = first_article.a.img['src']\n",
    "    except:\n",
    "        image_src = ''\n",
    "    \n",
    "    date_time = ''\n",
    "    description = ''\n",
    "    data.append([title, source[1], source[2], permalink, image_src, date_time, description, date.today(), 'English'])\n",
    "    \n",
    "    for article in soup.find_all('div', class_='categorycolumn'):\n",
    "        #print('j' + str(j))\n",
    "        j = j +1\n",
    "        if j==1:\n",
    "            \n",
    "            try:\n",
    "                title = article.div.div.a['title']\n",
    "            except:\n",
    "                title = ''\n",
    "            try:\n",
    "                permalink = article.div.div.a['href']\n",
    "\n",
    "            except:\n",
    "                permalink = ''\n",
    "            try:\n",
    "                image_src = article.div.div.a.img['src']\n",
    "            except:\n",
    "                image_src = ''\n",
    "                \n",
    "            date_time = ''\n",
    "            description = ''\n",
    "            data.append([title, source[1], source[2], permalink, image_src, date_time, description, date.today(), 'English'])\n",
    "        elif j>1:\n",
    "            article = article.find('div', class_='row').find('div', class_='respnb1')\n",
    "            try:\n",
    "                title = article.a['title']\n",
    "            except:\n",
    "                title = ''\n",
    "            try:\n",
    "                permalink = article.a['href']\n",
    "\n",
    "            except:\n",
    "                permalink = ''\n",
    "            try:\n",
    "                image_src = article.a.img['src']\n",
    "            except:\n",
    "                image_src = ''\n",
    "            date_time = ''\n",
    "            description = ''\n",
    "            data.append([title, source[1], source[2], permalink, image_src, date_time, description, date.today(), 'English'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources7 = [[\"https://dunyanews.tv/en/World\", \"International\", \"Dunya\"],\n",
    "            [\"https://dunyanews.tv/en/Cricket\", \"Sports\", \"Dunya\"], \n",
    "            [\"https://dunyanews.tv/en/Pakistan\", \"Local\", \"Dunya\"],\n",
    "            [\"https://dunyanews.tv/en/Technology\", \"IT/Science\", \"Dunya\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these webpages have different style of posts on top\n",
    "i = 0\n",
    "for source in sources7:\n",
    "    #print('i' + str(i))\n",
    "    j=0\n",
    "    \n",
    "    sourceHtml = requests.get(source[0]).text\n",
    "    soup = BeautifulSoup(sourceHtml, 'lxml')\n",
    "    \n",
    "    for article in soup.find_all('article'):\n",
    "        #print('j' + str(j))\n",
    "        j = j +1\n",
    "        if j<9:\n",
    "            try:\n",
    "                title = article.h3.text\n",
    "                print(title)\n",
    "            except:\n",
    "                title = ''\n",
    "            try:\n",
    "                permalink = article.div.a['href']\n",
    "                print(permalink)\n",
    "            except:\n",
    "                permalink = ''\n",
    "                print(permalink)\n",
    "            try:\n",
    "                image_src = article.div.a.img['src']\n",
    "                print(image_src)\n",
    "            except:\n",
    "                image_src = ''\n",
    "                print(image_src)\n",
    "            try:\n",
    "                date_time = article.find('div', class_='post_text_wrapper').ul.li.a.text\n",
    "                print(date_time)\n",
    "            except:\n",
    "                date_time = ''\n",
    "                print(date_time)\n",
    "            try:\n",
    "                description = article.find('div', class_='text').text\n",
    "                print(description)\n",
    "            except:\n",
    "                description = ''\n",
    "                print(description)\n",
    "            \n",
    "            data.append([title, source[1], source[2], 'https://dunyanews.tv'+permalink, image_src, date_time, description, date.today(), 'English'])\n",
    "        else:\n",
    "            print('-------sss')\n",
    "            try:\n",
    "                title = article.h3.text\n",
    "                print(title)\n",
    "            except:\n",
    "                title = ''\n",
    "            try:\n",
    "                permalink = article.h3.a['href']\n",
    "                print(permalink)\n",
    "            except:\n",
    "                permalink = ''\n",
    "                print(permalink)\n",
    "            try:\n",
    "                image_src = article.div.a.img['src']\n",
    "                print(image_src)\n",
    "            except:\n",
    "                image_src = ''\n",
    "                print(image_src)\n",
    "            try:\n",
    "                date_time = article.ul.li.a.text\n",
    "                print(date_time)\n",
    "            except:\n",
    "                date_time = ''\n",
    "                print(date_time)\n",
    "            try:\n",
    "                description = article.find('div', class_='text').text\n",
    "                print(description)\n",
    "            except:\n",
    "                description = ''\n",
    "                print(description)\n",
    "            \n",
    "            data.append([title, source[1], source[2], 'https://dunyanews.tv'+permalink, image_src, date_time, description, date.today(), 'English'])\n",
    "            print('-------------------------------')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns = ['title','category', 'chanel', 'permalink', 'image_src', 'date_time', 'description', 'fetching_date', 'Language'])\n",
    "df\n",
    "df.to_csv('5webs data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'soup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-54bd9b38bf2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0marticle\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'article'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'src'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'soup' is not defined"
     ]
    }
   ],
   "source": [
    "for article in soup.find_all('article'):\n",
    "    try:\n",
    "        print(article.h3.text)\n",
    "        print(article.div.a['href'])\n",
    "        print(article.div.a.img['src'])\n",
    "        print(article.find('div', class_='text').text)\n",
    "        print(article.find('div', class_='post_text_wrapper').ul.li.a.text)\n",
    "        print(article.ul.li.a.text)\n",
    "    except:\n",
    "        print('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>chanel</th>\n",
       "      <th>permalink</th>\n",
       "      <th>image_src</th>\n",
       "      <th>date_time</th>\n",
       "      <th>description</th>\n",
       "      <th>fetching_date</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In pictures: Usman Mukhtar answers questions a...</td>\n",
       "      <td>LifeStyle/Culture</td>\n",
       "      <td>SAMAA</td>\n",
       "      <td>https://www.samaa.tv/lifeandstyle/2021/04/in-p...</td>\n",
       "      <td>https://www.samaa.tv/wp-content/uploads/2021/0...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bengali writer under fire for tweet against cr...</td>\n",
       "      <td>LifeStyle/Culture</td>\n",
       "      <td>SAMAA</td>\n",
       "      <td>https://www.samaa.tv/culture/2021/04/taslima-n...</td>\n",
       "      <td>https://www.samaa.tv/wp-content/uploads/2021/0...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>LifeStyle/Culture</td>\n",
       "      <td>SAMAA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‘Mrs Sri Lanka’ stripped of crown after bogus ...</td>\n",
       "      <td>LifeStyle/Culture</td>\n",
       "      <td>SAMAA</td>\n",
       "      <td>https://www.samaa.tv/lifeandstyle/2021/04/mrs-...</td>\n",
       "      <td>https://www.samaa.tv/wp-content/uploads/2021/0...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Russia fines TikTok over calls for minors to j...</td>\n",
       "      <td>LifeStyle/Culture</td>\n",
       "      <td>SAMAA</td>\n",
       "      <td>https://www.samaa.tv/lifeandstyle/2021/04/russ...</td>\n",
       "      <td>https://www.samaa.tv/wp-content/uploads/2021/0...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Porsche unveils two new electric bicycles</td>\n",
       "      <td>IT/Science</td>\n",
       "      <td>SAMAA</td>\n",
       "      <td>https://www.samaa.tv/technology/2021/03/porsch...</td>\n",
       "      <td>https://www.samaa.tv/wp-content/uploads/2021/0...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Scientists searching for traces of life behind...</td>\n",
       "      <td>IT/Science</td>\n",
       "      <td>SAMAA</td>\n",
       "      <td>https://www.samaa.tv/technology/2021/03/scient...</td>\n",
       "      <td>https://www.samaa.tv/wp-content/uploads/2021/0...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>WhatsApp introduces voice, video calling from ...</td>\n",
       "      <td>IT/Science</td>\n",
       "      <td>SAMAA</td>\n",
       "      <td>https://www.samaa.tv/technology/2021/03/whatsa...</td>\n",
       "      <td>https://www.samaa.tv/wp-content/uploads/2021/0...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Six PlayStation VR games that have everyone ta...</td>\n",
       "      <td>IT/Science</td>\n",
       "      <td>SAMAA</td>\n",
       "      <td>https://www.samaa.tv/technology/2021/03/six-pl...</td>\n",
       "      <td>https://www.samaa.tv/wp-content/uploads/2021/0...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Someone has brought Bhagat Singh to life—and i...</td>\n",
       "      <td>IT/Science</td>\n",
       "      <td>SAMAA</td>\n",
       "      <td>https://www.samaa.tv/culture/2021/03/someone-h...</td>\n",
       "      <td>https://www.samaa.tv/wp-content/uploads/2021/0...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title           category  \\\n",
       "0   In pictures: Usman Mukhtar answers questions a...  LifeStyle/Culture   \n",
       "1   Bengali writer under fire for tweet against cr...  LifeStyle/Culture   \n",
       "2                                                      LifeStyle/Culture   \n",
       "3   ‘Mrs Sri Lanka’ stripped of crown after bogus ...  LifeStyle/Culture   \n",
       "4   Russia fines TikTok over calls for minors to j...  LifeStyle/Culture   \n",
       "..                                                ...                ...   \n",
       "63          Porsche unveils two new electric bicycles         IT/Science   \n",
       "64  Scientists searching for traces of life behind...         IT/Science   \n",
       "65  WhatsApp introduces voice, video calling from ...         IT/Science   \n",
       "66  Six PlayStation VR games that have everyone ta...         IT/Science   \n",
       "67  Someone has brought Bhagat Singh to life—and i...         IT/Science   \n",
       "\n",
       "   chanel                                          permalink  \\\n",
       "0   SAMAA  https://www.samaa.tv/lifeandstyle/2021/04/in-p...   \n",
       "1   SAMAA  https://www.samaa.tv/culture/2021/04/taslima-n...   \n",
       "2   SAMAA                                                      \n",
       "3   SAMAA  https://www.samaa.tv/lifeandstyle/2021/04/mrs-...   \n",
       "4   SAMAA  https://www.samaa.tv/lifeandstyle/2021/04/russ...   \n",
       "..    ...                                                ...   \n",
       "63  SAMAA  https://www.samaa.tv/technology/2021/03/porsch...   \n",
       "64  SAMAA  https://www.samaa.tv/technology/2021/03/scient...   \n",
       "65  SAMAA  https://www.samaa.tv/technology/2021/03/whatsa...   \n",
       "66  SAMAA  https://www.samaa.tv/technology/2021/03/six-pl...   \n",
       "67  SAMAA  https://www.samaa.tv/culture/2021/03/someone-h...   \n",
       "\n",
       "                                            image_src date_time description  \\\n",
       "0   https://www.samaa.tv/wp-content/uploads/2021/0...                         \n",
       "1   https://www.samaa.tv/wp-content/uploads/2021/0...                         \n",
       "2                                                                             \n",
       "3   https://www.samaa.tv/wp-content/uploads/2021/0...                         \n",
       "4   https://www.samaa.tv/wp-content/uploads/2021/0...                         \n",
       "..                                                ...       ...         ...   \n",
       "63  https://www.samaa.tv/wp-content/uploads/2021/0...                         \n",
       "64  https://www.samaa.tv/wp-content/uploads/2021/0...                         \n",
       "65  https://www.samaa.tv/wp-content/uploads/2021/0...                         \n",
       "66  https://www.samaa.tv/wp-content/uploads/2021/0...                         \n",
       "67  https://www.samaa.tv/wp-content/uploads/2021/0...                         \n",
       "\n",
       "   fetching_date Language  \n",
       "0     2021-04-07  English  \n",
       "1     2021-04-07  English  \n",
       "2     2021-04-07  English  \n",
       "3     2021-04-07  English  \n",
       "4     2021-04-07  English  \n",
       "..           ...      ...  \n",
       "63    2021-04-07  English  \n",
       "64    2021-04-07  English  \n",
       "65    2021-04-07  English  \n",
       "66    2021-04-07  English  \n",
       "67    2021-04-07  English  \n",
       "\n",
       "[68 rows x 9 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
